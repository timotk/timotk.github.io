<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Enforce and Validate LLM Output with Pydantic | Timo's Blog</title><meta name=keywords content="python,llm,openai,gpt,pydantic"><meta name=description content="Large Language Models (LLMs) excel in generating text but often struggle to produce structured output. By leveraging Pydantic&rsquo;s type validation and prompt engineering, we can enforce and validate the output generated by LLMs.
All code examples in this blog post are written in Python. The LLM used is OpenAI&rsquo;s gpt-3.5-turbo.
Query the LLM To query the LLM, we use the following function:
import openai def query(prompt: str) -> str: &#34;&#34;&#34;Query the LLM with the given prompt."><meta name=author content="Timo"><link rel=canonical href=https://timotk.github.io/posts/enforce-validate-llm-output-pydantic/><link crossorigin=anonymous href=/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://timotk.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://timotk.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://timotk.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://timotk.github.io/apple-touch-icon.png><link rel=mask-icon href=https://timotk.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Enforce and Validate LLM Output with Pydantic"><meta property="og:description" content="Large Language Models (LLMs) excel in generating text but often struggle to produce structured output. By leveraging Pydantic&rsquo;s type validation and prompt engineering, we can enforce and validate the output generated by LLMs.
All code examples in this blog post are written in Python. The LLM used is OpenAI&rsquo;s gpt-3.5-turbo.
Query the LLM To query the LLM, we use the following function:
import openai def query(prompt: str) -> str: &#34;&#34;&#34;Query the LLM with the given prompt."><meta property="og:type" content="article"><meta property="og:url" content="https://timotk.github.io/posts/enforce-validate-llm-output-pydantic/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-07T13:00:00+02:00"><meta property="article:modified_time" content="2023-08-07T13:00:00+02:00"><meta property="og:site_name" content="Timo's Blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="Enforce and Validate LLM Output with Pydantic"><meta name=twitter:description content="Large Language Models (LLMs) excel in generating text but often struggle to produce structured output. By leveraging Pydantic&rsquo;s type validation and prompt engineering, we can enforce and validate the output generated by LLMs.
All code examples in this blog post are written in Python. The LLM used is OpenAI&rsquo;s gpt-3.5-turbo.
Query the LLM To query the LLM, we use the following function:
import openai def query(prompt: str) -> str: &#34;&#34;&#34;Query the LLM with the given prompt."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://timotk.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Enforce and Validate LLM Output with Pydantic","item":"https://timotk.github.io/posts/enforce-validate-llm-output-pydantic/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Enforce and Validate LLM Output with Pydantic","name":"Enforce and Validate LLM Output with Pydantic","description":"Large Language Models (LLMs) excel in generating text but often struggle to produce structured output. By leveraging Pydantic\u0026rsquo;s type validation and prompt engineering, we can enforce and validate the output generated by LLMs.\nAll code examples in this blog post are written in Python. The LLM used is OpenAI\u0026rsquo;s gpt-3.5-turbo.\nQuery the LLM To query the LLM, we use the following function:\nimport openai def query(prompt: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Query the LLM with the given prompt.","keywords":["python","llm","openai","gpt","pydantic"],"articleBody":"Large Language Models (LLMs) excel in generating text but often struggle to produce structured output. By leveraging Pydantic’s type validation and prompt engineering, we can enforce and validate the output generated by LLMs.\nAll code examples in this blog post are written in Python. The LLM used is OpenAI’s gpt-3.5-turbo.\nQuery the LLM To query the LLM, we use the following function:\nimport openai def query(prompt: str) -\u003e str: \"\"\"Query the LLM with the given prompt.\"\"\" completion = openai.ChatCompletion.create( model=\"gpt-3.5-turbo\", messages=[ { \"role\": \"user\", \"content\": prompt, } ], temperature=0.0, ) return completion.choices[0].message.content Query the model We can query the model with a simple question:\nresponse = query(\"What is the largest planet in our solar system?\") print(response) 'The largest planet in our solar system is Jupiter.' Enforcing JSON output with a prompt In our prompt, we can ask the LLM to respond in a certain format:\nprompt = \"\"\" I will ask you questions and you will respond. Your response should be in the following format: ```json { \"thought\": \"How you think about the question\", \"answer\": \"The answer to the question\" } ``` \"\"\" Then, we query the model:\nquestion = \"What is the largest planet in our solar system?\" response = query(prompt + question) print(response) '{ \"thought\": \"This is a factual question that can be answered with scientific knowledge.\", \"answer\": \"The largest planet in our solar system is Jupiter.\" }' This is great, because we can easily parse the structured output:\nimport json parsed_response = json.loads(response) print(parsed_response[\"answer\"]) 'The largest planet in our solar system is Jupiter.' Validating the output from pydantic import BaseModel class ThoughtAnswerResponse(BaseModel): thought: str answer: str raw_response = query(prompt) # Note: When you are using pydantic\u003c2.0, use parse_raw instead of model_validate_json validated_response = ThoughtAnswerResponse.model_validate_json(raw_response) print(validated_response) thought='This is a factual question that can be answered with scientific knowledge.' answer='The largest planet in our solar system is Jupiter.' print(type(validated_response)) \u003cclass 'ThoughtAnswerResponse'\u003e Using the Pydantic model in the prompt At this moment, we describe our response format in two places:\na JSON description in our prompt a corresponding Pydantic model When we want to update the response format, we need to change both the prompt and the Pydantic model. This can cause inconsistencies.\nWe can solve this by exporting the Pydantic model to a JSON schema and adding the schema to the prompt. This will make the response and the Pydantic model consistent.\nresponse_schema_dict = ThoughtAnswerResponse.model_json_schema() response_schema_json = json.dumps(response_schema_dict, indent=2) prompt = f\"\"\" I will ask you questions, and you will respond. Your response should be in the following format: ```json {response_schema_json} ``` \"\"\" The prompt will now look like this:\nI will ask you questions, and you will respond. Your response should be in the following format: ```json { \"properties\": { \"thought\": { \"title\": \"Thought\", \"type\": \"string\" }, \"answer\": { \"title\": \"Answer\", \"type\": \"string\" } }, \"required\": [\"thought\", \"answer\"], \"title\": \"ThoughtAnswerResponse\", \"type\": \"object\" } The response will look like this:\n{ \"thought\": \"The largest planet in our solar system is Jupiter.\", \"answer\": \"Jupiter\" } Now, whenever you change the Pydantic model, the corresponding schema will be put in the prompt. Note that the schema has become more complex than it was before. One benefit is that it allows us to be more specific in what responses we require.\nError handling The LLM may still produce results that are not consistent with our model. We can add some code to catch this:\nfrom pydantic import ValidationError try: validated_response = ThoughtAnswerResponse.model_validate_json(raw_response) except ValidationError as e: print(\"Unable to validate LLM response.\") # Add your own error handling here raise e Enforce specific values using a Literal Sometimes, you want to enforce the use of specific values for a given field. We add the field “difficulty” to our response object. The LLM should use it to provide information about the difficulty of the question. In a regular prompt, we would do the following:\nprompt = \"\"\"Your response should be in the following format: ```json { \"thought\": \"How you think about the question\", \"answer\": \"The answer to the question\", \"difficulty\": \"How difficult the question was. One of easy, medium or hard\" } ``` \"\"\" Of course, the model could potentially still use other values. To validate it, we would need to write custom code.\nWith Pydantic, it is a lot easier. We create a new type called Difficulty using a Literal. A Literal allows us to specify the use of a select list of values. We add a Difficulty type hint to the difficulty field in our Pydantic model:\nfrom typing import Literal from pydantic import BaseModel # We create a new type Difficulty = Literal[\"easy\", \"medium\", \"hard\"] class ThoughtAnswerResponse(BaseModel): thought: str answer: str difficulty: Difficulty The LLM responds may respond with a value we do not allow:\n{ \"thought\": \"The largest planet in our solar system is Jupiter.\", \"answer\": \"Jupiter\", \"difficulty\": \"Unknown\" } When we parse this result, Pydantic will validate the values for the difficulty field. Unknown does not match one of the values specified in the Literal type we have defined. So we get the following error:\nvalidated_response = ThoughtAnswerResponse.model_validate_json(response) ValidationError: 1 validation error for ThoughtAnswerResponse difficulty Input should be 'easy', 'medium' or 'hard' [type=literal_error, input_value='Unknown', input_type=str] Conclusion By using Pydantic and prompt engineering, you can enforce and validate the output of LLMs. This provides you with greater control of the LLM output and allow you to build more robust AI systems.\n","wordCount":"891","inLanguage":"en","datePublished":"2023-08-07T13:00:00+02:00","dateModified":"2023-08-07T13:00:00+02:00","author":{"@type":"Person","name":"Timo"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://timotk.github.io/posts/enforce-validate-llm-output-pydantic/"},"publisher":{"@type":"Organization","name":"Timo's Blog","logo":{"@type":"ImageObject","url":"https://timotk.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://timotk.github.io accesskey=h title="Timo's Blog (Alt + H)">Timo's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://timotk.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://timotk.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://timotk.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Enforce and Validate LLM Output with Pydantic</h1><div class=post-meta><span title='2023-08-07 13:00:00 +0200 +0200'>August 7, 2023</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;891 words&nbsp;·&nbsp;Timo&nbsp;|&nbsp;<a href=https://github.com/timotk/timotk.github.io/tree/main/content/posts/enforce-validate-llm-output-pydantic.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>Large Language Models (LLMs) excel in generating text but often struggle to produce structured output.
By leveraging <a href=https://docs.pydantic.dev/latest/>Pydantic</a>&rsquo;s type validation and prompt engineering, we can enforce and validate the output generated by LLMs.</p><p><em>All code examples in this blog post are written in Python. The LLM used is <a href=https://platform.openai.com/docs/guides/gpt>OpenAI&rsquo;s gpt-3.5-turbo</a>.</em></p><h1 id=query-the-llm>Query the LLM<a hidden class=anchor aria-hidden=true href=#query-the-llm>#</a></h1><p>To query the LLM, we use the following function:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>openai</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>query</span><span class=p>(</span><span class=n>prompt</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Query the LLM with the given prompt.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>completion</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>ChatCompletion</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-3.5-turbo&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>prompt</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>completion</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span></code></pre></div><h1 id=query-the-model>Query the model<a hidden class=anchor aria-hidden=true href=#query-the-model>#</a></h1><p>We can query the model with a simple question:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>query</span><span class=p>(</span><span class=s2>&#34;What is the largest planet in our solar system?&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=s1>&#39;The largest planet in our solar system is Jupiter.&#39;</span>
</span></span></code></pre></div><h1 id=enforcing-json-output-with-a-prompt>Enforcing JSON output with a prompt<a hidden class=anchor aria-hidden=true href=#enforcing-json-output-with-a-prompt>#</a></h1><p>In our prompt, we can ask the LLM to respond in a certain format:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>I will ask you questions and you will respond. Your response should be in the following format:
</span></span></span><span class=line><span class=cl><span class=s2>```json
</span></span></span><span class=line><span class=cl><span class=s2>{
</span></span></span><span class=line><span class=cl><span class=s2>	&#34;thought&#34;: &#34;How you think about the question&#34;,
</span></span></span><span class=line><span class=cl><span class=s2>	&#34;answer&#34;: &#34;The answer to the question&#34;
</span></span></span><span class=line><span class=cl><span class=s2>}
</span></span></span><span class=line><span class=cl><span class=s2>```
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span></code></pre></div><p>Then, we query the model:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>question</span> <span class=o>=</span> <span class=s2>&#34;What is the largest planet in our solar system?&#34;</span>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>query</span><span class=p>(</span><span class=n>prompt</span> <span class=o>+</span> <span class=n>question</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=s1>&#39;{</span>
</span></span><span class=line><span class=cl>	<span class=s2>&#34;thought&#34;</span><span class=p>:</span> <span class=s2>&#34;This is a factual question that can be answered with scientific knowledge.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>	<span class=s2>&#34;answer&#34;</span><span class=p>:</span> <span class=s2>&#34;The largest planet in our solar system is Jupiter.&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span><span class=s1>&#39;</span>
</span></span></code></pre></div><p>This is great, because we can easily parse the structured output:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>parsed_response</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>parsed_response</span><span class=p>[</span><span class=s2>&#34;answer&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=s1>&#39;The largest planet in our solar system is Jupiter.&#39;</span>
</span></span></code></pre></div><h1 id=validating-the-output>Validating the output<a hidden class=anchor aria-hidden=true href=#validating-the-output>#</a></h1><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pydantic</span> <span class=kn>import</span> <span class=n>BaseModel</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ThoughtAnswerResponse</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>thought</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl>    <span class=n>answer</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>raw_response</span> <span class=o>=</span> <span class=n>query</span><span class=p>(</span><span class=n>prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Note: When you are using pydantic&lt;2.0, use parse_raw instead of model_validate_json</span>
</span></span><span class=line><span class=cl><span class=n>validated_response</span> <span class=o>=</span> <span class=n>ThoughtAnswerResponse</span><span class=o>.</span><span class=n>model_validate_json</span><span class=p>(</span><span class=n>raw_response</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>validated_response</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>thought</span><span class=o>=</span><span class=s1>&#39;This is a factual question that can be answered with scientific knowledge.&#39;</span> <span class=n>answer</span><span class=o>=</span><span class=s1>&#39;The largest planet in our solar system is Jupiter.&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=nb>type</span><span class=p>(</span><span class=n>validated_response</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=o>&lt;</span><span class=k>class</span> <span class=err>&#39;</span><span class=nc>ThoughtAnswerResponse</span><span class=s1>&#39;&gt;</span>
</span></span></code></pre></div><h1 id=using-the-pydantic-model-in-the-prompt>Using the Pydantic model in the prompt<a hidden class=anchor aria-hidden=true href=#using-the-pydantic-model-in-the-prompt>#</a></h1><p>At this moment, we describe our response format in two places:</p><ul><li>a JSON description in our prompt</li><li>a corresponding Pydantic model</li></ul><p>When we want to update the response format, we need to change both the prompt and the Pydantic model. This can cause inconsistencies.</p><p>We can solve this by <a href=https://docs.pydantic.dev/latest/usage/json_schema/>exporting the Pydantic model to a JSON schema</a> and adding the schema to the prompt. This will make the response and the Pydantic model consistent.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>response_schema_dict</span> <span class=o>=</span> <span class=n>ThoughtAnswerResponse</span><span class=o>.</span><span class=n>model_json_schema</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>response_schema_json</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>response_schema_dict</span><span class=p>,</span> <span class=n>indent</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>I will ask you questions, and you will respond.
</span></span></span><span class=line><span class=cl><span class=s2>Your response should be in the following format:
</span></span></span><span class=line><span class=cl><span class=s2>```json
</span></span></span><span class=line><span class=cl><span class=s2></span><span class=si>{</span><span class=n>response_schema_json</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>```
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span></code></pre></div><p>The prompt will now look like this:</p><pre tabindex=0><code>I will ask you questions, and you will respond. Your response should be in the following format:
```json
{
	&#34;properties&#34;: {
		&#34;thought&#34;: { &#34;title&#34;: &#34;Thought&#34;, &#34;type&#34;: &#34;string&#34; },
		&#34;answer&#34;: { &#34;title&#34;: &#34;Answer&#34;, &#34;type&#34;: &#34;string&#34; }
	},
	&#34;required&#34;: [&#34;thought&#34;, &#34;answer&#34;],
	&#34;title&#34;: &#34;ThoughtAnswerResponse&#34;,
	&#34;type&#34;: &#34;object&#34;
}
</code></pre><p>The response will look like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;thought&#34;</span><span class=p>:</span> <span class=s2>&#34;The largest planet in our solar system is Jupiter.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;answer&#34;</span><span class=p>:</span> <span class=s2>&#34;Jupiter&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Now, whenever you change the Pydantic model, the corresponding schema will be put in the prompt. Note that the schema has become more complex than it was before. One benefit is that it allows us to be more specific in what responses we require.</p><h1 id=error-handling>Error handling<a hidden class=anchor aria-hidden=true href=#error-handling>#</a></h1><p>The LLM may still produce results that are not consistent with our model. We can add some code to catch this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pydantic</span> <span class=kn>import</span> <span class=n>ValidationError</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>validated_response</span> <span class=o>=</span> <span class=n>ThoughtAnswerResponse</span><span class=o>.</span><span class=n>model_validate_json</span><span class=p>(</span><span class=n>raw_response</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>except</span> <span class=n>ValidationError</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Unable to validate LLM response.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Add your own error handling here</span>
</span></span><span class=line><span class=cl>    <span class=k>raise</span> <span class=n>e</span>
</span></span></code></pre></div><h1 id=enforce-specific-values-using-a-literal>Enforce specific values using a Literal<a hidden class=anchor aria-hidden=true href=#enforce-specific-values-using-a-literal>#</a></h1><p>Sometimes, you want to enforce the use of specific values for a given field. We add the field &ldquo;difficulty&rdquo; to our response object. The LLM should use it to provide information about the difficulty of the question. In a regular prompt, we would do the following:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;Your response should be in the following format:
</span></span></span><span class=line><span class=cl><span class=s2>```json
</span></span></span><span class=line><span class=cl><span class=s2>{
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;thought&#34;: &#34;How you think about the question&#34;,
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;answer&#34;: &#34;The answer to the question&#34;,
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;difficulty&#34;: &#34;How difficult the question was. One of easy, medium or hard&#34;
</span></span></span><span class=line><span class=cl><span class=s2>}
</span></span></span><span class=line><span class=cl><span class=s2>```
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span></code></pre></div><p>Of course, the model could potentially still use other values. To validate it, we would need to write custom code.</p><p>With Pydantic, it is a lot easier. We create a new type called <code>Difficulty</code> using a <a href=https://docs.python.org/3/library/typing.html#typing.Literal>Literal</a>.
A Literal allows us to specify the use of a select list of values.
We add a <code>Difficulty</code> type hint to the <code>difficulty</code> field in our Pydantic model:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Literal</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pydantic</span> <span class=kn>import</span> <span class=n>BaseModel</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># We create a new type</span>
</span></span><span class=line><span class=cl><span class=n>Difficulty</span> <span class=o>=</span> <span class=n>Literal</span><span class=p>[</span><span class=s2>&#34;easy&#34;</span><span class=p>,</span> <span class=s2>&#34;medium&#34;</span><span class=p>,</span> <span class=s2>&#34;hard&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ThoughtAnswerResponse</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>thought</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl>    <span class=n>answer</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl>    <span class=n>difficulty</span><span class=p>:</span> <span class=n>Difficulty</span>
</span></span></code></pre></div><p>The LLM responds may respond with a value we do not allow:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;thought&#34;</span><span class=p>:</span> <span class=s2>&#34;The largest planet in our solar system is Jupiter.&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;answer&#34;</span><span class=p>:</span> <span class=s2>&#34;Jupiter&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;difficulty&#34;</span><span class=p>:</span> <span class=s2>&#34;Unknown&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>When we parse this result, Pydantic will validate the values for the <code>difficulty</code> field. <code>Unknown</code> does not match one of the values specified in the Literal type we have defined. So we get the following error:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>validated_response</span> <span class=o>=</span> <span class=n>ThoughtAnswerResponse</span><span class=o>.</span><span class=n>model_validate_json</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ValidationError</span><span class=p>:</span> <span class=mi>1</span> <span class=n>validation</span> <span class=n>error</span> <span class=k>for</span> <span class=n>ThoughtAnswerResponse</span>
</span></span><span class=line><span class=cl><span class=n>difficulty</span>
</span></span><span class=line><span class=cl>    <span class=n>Input</span> <span class=n>should</span> <span class=n>be</span> <span class=s1>&#39;easy&#39;</span><span class=p>,</span> <span class=s1>&#39;medium&#39;</span> <span class=ow>or</span> <span class=s1>&#39;hard&#39;</span> <span class=p>[</span><span class=nb>type</span><span class=o>=</span><span class=n>literal_error</span><span class=p>,</span> <span class=n>input_value</span><span class=o>=</span><span class=s1>&#39;Unknown&#39;</span><span class=p>,</span> <span class=n>input_type</span><span class=o>=</span><span class=nb>str</span><span class=p>]</span>
</span></span></code></pre></div><h1 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h1><p>By using Pydantic and prompt engineering, you can enforce and validate the output of LLMs. This provides you with greater control of the LLM output and allow you to build more robust AI systems.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://timotk.github.io/tags/python/>python</a></li><li><a href=https://timotk.github.io/tags/llm/>llm</a></li><li><a href=https://timotk.github.io/tags/openai/>openai</a></li><li><a href=https://timotk.github.io/tags/gpt/>gpt</a></li><li><a href=https://timotk.github.io/tags/pydantic/>pydantic</a></li></ul><nav class=paginav><a class=next href=https://timotk.github.io/posts/a-terminal-spinner-in-python/><span class=title>Next »</span><br><span>A Terminal Spinner in Python</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://timotk.github.io>Timo's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>